\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:polimi}{{\caption@xref {fig:polimi}{ on input line 67}}{1}{}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction (Course motivation)}{4}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Data-driven Decision Making for Data-driven Organizations}{4}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Solving problems with Big Data, Data Science and ... Data Engineering}{4}{subsection.1.2}\protected@file@percent }
\newlabel{fig:data-analysis}{{\caption@xref {fig:data-analysis}{ on input line 89}}{4}{Solving problems with Big Data, Data Science and ... Data Engineering}{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Up until '90s the data available was growing together with our analytical and execution capabilities.\relax }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:big-data}{{\caption@xref {fig:big-data}{ on input line 94}}{4}{Solving problems with Big Data, Data Science and ... Data Engineering}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces With the new millenium we have the appearence of Big Data. Data availability is growing fast and the digital revolution gap is growing.\relax }}{4}{figure.caption.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}What's Big Data?}{5}{subsubsection.1.2.1}\protected@file@percent }
\newlabel{fig:4v}{{\caption@xref {fig:4v}{ on input line 108}}{5}{What's Big Data?}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces With the new millenium we have the appearence of Big Data. Data availability is growing fast and the digital revolution gap is growing.\relax }}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:crude-oil}{{\caption@xref {fig:crude-oil}{ on input line 120}}{5}{What's Big Data?}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}What's Data Science}{6}{subsubsection.1.2.2}\protected@file@percent }
\newlabel{fig:data-scientists}{{\caption@xref {fig:data-scientists}{ on input line 134}}{6}{What's Data Science}{figure.caption.7}{}}
\newlabel{fig:statistical-modeling}{{\caption@xref {fig:statistical-modeling}{ on input line 143}}{6}{What's Data Science}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}What's Data Engineering}{7}{subsubsection.1.2.3}\protected@file@percent }
\newlabel{fig:new1}{{\caption@xref {fig:new1}{ on input line 159}}{7}{What's Data Engineering}{figure.caption.9}{}}
\newlabel{fig:new11}{{\caption@xref {fig:new11}{ on input line 163}}{7}{What's Data Engineering}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Instead of looking for the perfect exact data, measure everything and \textbf  {leverage more of the data being captured.} With a large enough dataset at some point we reach the same result (Central Limit Theorem).\relax }}{7}{figure.caption.10}\protected@file@percent }
\newlabel{fig:new2}{{\caption@xref {fig:new2}{ on input line 168}}{7}{What's Data Engineering}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Data-driven exploration looking for correlation.} For instance, your butcher sells both pure meat and semi-prepared dishes because he knows that if you see the variety of products that he prepares and sells, you will probably notice something that you like!\relax }}{7}{figure.caption.11}\protected@file@percent }
\newlabel{fig:new3}{{\caption@xref {fig:new3}{ on input line 175}}{8}{What's Data Engineering}{figure.caption.12}{}}
\newlabel{fig:new33}{{\caption@xref {fig:new33}{ on input line 179}}{8}{What's Data Engineering}{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Reduce effort required to leverage data.} If you can do it by hand it is not said that you can do it automatically. Is hard to do things at scale.\relax }}{8}{figure.caption.13}\protected@file@percent }
\newlabel{fig:new4}{{\caption@xref {fig:new4}{ on input line 184}}{8}{What's Data Engineering}{figure.caption.14}{}}
\newlabel{fig:new44}{{\caption@xref {fig:new44}{ on input line 188}}{8}{What's Data Engineering}{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Leverage data as it is captured.}\relax }}{8}{figure.caption.15}\protected@file@percent }
\newlabel{fig:data-eng-era}{{\caption@xref {fig:data-eng-era}{ on input line 194}}{8}{What's Data Engineering}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}No SQL Intro}{9}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Big Data Platforms: Architectures, Features and System}{9}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Big Data vs Traditional Data}{9}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{fig:big-vs-traditional}{{\caption@xref {fig:big-vs-traditional}{ on input line 202}}{9}{Big Data vs Traditional Data}{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Big Data vs. Traditional Data\relax }}{9}{figure.caption.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \textbf  {Schema-on-write}: the rigid and traditional strategy (relational data) in which a complex schema is applied after a long lasting discussing. Here we collect the data from different sources, ensuring that it is compatible with our schema and then we make analysis on that.\relax }}{9}{figure.caption.18}\protected@file@percent }
\newlabel{fig:sow}{{9}{9}{\textbf {Schema-on-write}: the rigid and traditional strategy (relational data) in which a complex schema is applied after a long lasting discussing. Here we collect the data from different sources, ensuring that it is compatible with our schema and then we make analysis on that.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \textbf  {Schema-on-read}: schema-less approach (document-based data) in which we collect and load data first and ask questions/queries later. All data are kept and the minimal schema for an analysis is applied only when needed. New analysis can then be introduced in any point in time.\relax }}{9}{figure.caption.18}\protected@file@percent }
\newlabel{fig:sor}{{10}{9}{\textbf {Schema-on-read}: schema-less approach (document-based data) in which we collect and load data first and ask questions/queries later. All data are kept and the minimal schema for an analysis is applied only when needed. New analysis can then be introduced in any point in time.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}The Concept of Data Lake}{10}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Data lake\relax }}{10}{figure.caption.19}\protected@file@percent }
\newlabel{fig:data-lake}{{11}{10}{Data lake\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Data Lake in process\relax }}{10}{figure.caption.19}\protected@file@percent }
\newlabel{fig:data-lake-process}{{12}{10}{Data Lake in process\relax }{figure.caption.19}{}}
\newlabel{fig:data-wrangling}{{\caption@xref {fig:data-wrangling}{ on input line 248}}{10}{The Concept of Data Lake}{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Data Wrangling\relax }}{10}{figure.caption.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Scalability}{11}{subsubsection.2.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Vertical Scalability\relax }}{11}{figure.caption.21}\protected@file@percent }
\newlabel{fig:vertical}{{14}{11}{Vertical Scalability\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Horizontal Scalability\relax }}{11}{figure.caption.21}\protected@file@percent }
\newlabel{fig:horizontal}{{15}{11}{Horizontal Scalability\relax }{figure.caption.21}{}}
\newlabel{fig:vertical-vs-horizontal}{{\caption@xref {fig:vertical-vs-horizontal}{ on input line 275}}{11}{Scalability}{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Vertical (Exponential) vs Horizontal (Linear) growth\relax }}{11}{figure.caption.22}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces The space within vertical (blue) and horizontal (red) scalable solution. On the left we see an high price gap between the blue and the red line for which the preferred solution is the vertical scalability. On the right is the contrary: the price is growing faster on the blue line while the horizontal scalable solution price is growing linearly.\relax }}{11}{figure.caption.23}\protected@file@percent }
\newlabel{fig:grey-area}{{17}{11}{The space within vertical (blue) and horizontal (red) scalable solution. On the left we see an high price gap between the blue and the red line for which the preferred solution is the vertical scalability. On the right is the contrary: the price is growing faster on the blue line while the horizontal scalable solution price is growing linearly.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The grey area moves in time. As a result, we can see that horizontal scalability now makes sense when we have to deal with 10TB of data.\relax }}{11}{figure.caption.23}\protected@file@percent }
\newlabel{fig:grey-area-in-time}{{18}{11}{The grey area moves in time. As a result, we can see that horizontal scalability now makes sense when we have to deal with 10TB of data.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}ACID vs. BASE and SQL vs. NoSQL}{12}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Transactional Properties}{12}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{fig:transactions}{{\caption@xref {fig:transactions}{ on input line 303}}{12}{Transactional Properties}{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Application and Transactions\relax }}{12}{figure.caption.24}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Transaction example\relax }}{12}{figure.caption.25}\protected@file@percent }
\newlabel{fig:t1}{{20}{12}{Transaction example\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Another Transaction example with rollback\relax }}{12}{figure.caption.25}\protected@file@percent }
\newlabel{fig:t2}{{21}{12}{Another Transaction example with rollback\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {paragraph}{ACID Properties of Transactions}{12}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}CAP Theorem}{13}{subsubsection.2.2.2}\protected@file@percent }
\newlabel{fig:ca}{{22a}{13}{\textbf {Consistency vs Availability}\relax }{figure.caption.27}{}}
\newlabel{sub@fig:ca}{{a}{13}{\textbf {Consistency vs Availability}\relax }{figure.caption.27}{}}
\newlabel{fig:cp}{{22b}{13}{\textbf {Consistency vs Performance}\relax }{figure.caption.27}{}}
\newlabel{sub@fig:cp}{{b}{13}{\textbf {Consistency vs Performance}\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces We need to choose between consistency and availability. According to the use case scenario, we can choose which one to favour. For example, \uline  {consistency should be preferred in banking applications}, where the transactions of money should be carefully saved and stored in a rigid flow to allow the correct functioning of the system. While almost \uline  {all the social media apps or streaming platforms may concentrate on availability} since if some data in the communication is lost or some user content are not presented in the latest version, the app can continue providing the service without creating any big issues to the user. Talking about \uline  {performance}, high consistency usually results in low performance while high performance results in low consistency.\relax }}{13}{figure.caption.27}\protected@file@percent }
\newlabel{fig:cap}{{22}{13}{We need to choose between consistency and availability. According to the use case scenario, we can choose which one to favour. For example, \uline {consistency should be preferred in banking applications}, where the transactions of money should be carefully saved and stored in a rigid flow to allow the correct functioning of the system. While almost \uline {all the social media apps or streaming platforms may concentrate on availability} since if some data in the communication is lost or some user content are not presented in the latest version, the app can continue providing the service without creating any big issues to the user. Talking about \uline {performance}, high consistency usually results in low performance while high performance results in low consistency.\relax }{figure.caption.27}{}}
\newlabel{fig:cap-theorem}{{\caption@xref {fig:cap-theorem}{ on input line 378}}{14}{CAP Theorem}{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Visual Guide to CAP Theorem\relax }}{14}{figure.caption.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}ACID vs. BASE properties}{14}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}The NoSQL World}{15}{subsubsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\uline  {Kind of NoSQL}}{15}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\uline  {Different types of NoSQL}}{15}{section*.30}\protected@file@percent }
\newlabel{fig:nosqltypes}{{\caption@xref {fig:nosqltypes}{ on input line 443}}{16}{\uline {Different types of NoSQL}}{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces NoSQL types\relax }}{16}{figure.caption.31}\protected@file@percent }
\newlabel{fig:nosqlfamtree}{{\caption@xref {fig:nosqlfamtree}{ on input line 460}}{16}{\uline {Different types of NoSQL}}{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Graph DB}{17}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Graph Theory}{17}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces A small social graph\relax }}{17}{figure.caption.33}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Publishing messages\relax }}{18}{figure.caption.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Useful definitions}{18}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces $V:= \{1,2,3,4,5,6\} - E: \{ \{1,2\},\{1,5\},\{2,3\},\{2,5\},\{3,4\},\{4,5\},\{4,6\}\}$\relax }}{19}{figure.caption.35}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Graph path and reachability\relax }}{19}{figure.caption.36}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Graph cycle\relax }}{19}{figure.caption.37}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces For example, in a GPS navigator we could use weight to specify duration, distance or traffic. The shortest path between two nodes is then calculated selecting the edges with the lowest weight.\relax }}{20}{figure.caption.38}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Nodes in $V_1$ connects only with nodes in $V_2$ (usually those are different categories of nodes e.g., Users and Posts)\relax }}{20}{figure.caption.39}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Exponential growth\relax }}{20}{figure.caption.40}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Example of Tree\relax }}{21}{figure.caption.41}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Node degree\relax }}{21}{figure.caption.42}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Node degree in directed graph\relax }}{21}{figure.caption.42}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Subgraph and Supergraph\relax }}{21}{figure.caption.43}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Graph Abstract Data Type (ADT)}{22}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces $|V|x|V|$ matrix $A=(a_{ij})$ such that $a_{ij}=1$ if $(i,j) \in E$ and $0$ otherwise.\relax }}{22}{figure.caption.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Graph Databases}{22}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Advantages of Graph Databases}{23}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Performance:}{23}{section*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Flexibility:}{23}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Agility:}{23}{section*.47}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Relational DB with intermediate join table\relax }}{23}{figure.caption.48}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Graph DB model. Much simpler!\relax }}{23}{figure.caption.48}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces Querying a graph is similar to pattern matching. First, we define a pattern (shape of (sub)graph that we are looking for) and then we look in the graph for that shape.\relax }}{24}{figure.caption.49}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Neo4J}{24}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces Neo4J software architecture. Each type of record (e.g., nodes, relationships) is stored in a separate and dedicated file. Traditional \textbf  {C}onsistency and \textbf  {Availability} support (no partitioning).\relax }}{24}{figure.caption.50}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Cypher}{25}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces This pattern describes three mutual friends. Here’s the equivalent ASCII art representation in Cypher: \leavevmode {\color  {blue}(emil)$\leftarrow $[:KNOWS]$-$(jim)$-$[:KNOWS]$\rightarrow $(ian)$-$[:KNOWS]$\rightarrow $(emil)} \relax }}{25}{figure.caption.51}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces Here we have bound each node to its identifier using its $name$ property and $Person$ label. The $emil$ identifer, for example, is bound to a node in the dataset with a label $Person$ and a $name$ property whose value is $Emil$. Anchoring parts of the pattern to real data in this way is normal Cypher practice.\relax }}{25}{figure.caption.52}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces \textbf  {Example query.} Find a node $n$ of type $Crew$ connected to $m$ with relations $r$ of type $Knows$ (from 1-step to *-steps in the relation) \relax }}{26}{figure.caption.54}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces \textbf  {Example query.} Aggregation can be used (count). WITH separates query parts explicitly, to declare the variables for the next part. SKIP skips results at the top and LIMIT limits the number of results. \relax }}{26}{figure.caption.55}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces List of patterns\relax }}{26}{figure.caption.57}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Stored procedures}{27}{section*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hints}{27}{section*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Key-Value DB}{27}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}How does a key-value database work?}{27}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Key Features}{28}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Redis}{28}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces Redis data types.\relax }}{29}{figure.caption.60}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces Redis commands. \href  {https://redis.io/commands}{Full command reference here}\relax }}{29}{figure.caption.60}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Scaling Redis}{30}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Redis topologies}{30}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{I - Standalone}{30}{section*.61}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{II - Sentinel}{31}{section*.63}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{III - Twemproxy}{31}{section*.65}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{IV - Cluster}{31}{section*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Redis Advantages}{32}{subsubsection.4.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {49}{\ignorespaces \href  {https://redislabs.com/blog/the-proven-redis-performance/}{NoSQL \& SQL response performance comparison}.   Num of operations per unit of time - Average query time\relax }}{32}{figure.caption.69}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Key-Value and Caching}{32}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}What is Caching?}{32}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Memcached}{34}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {50}{\ignorespaces Memcached PHP Client functions.\relax }}{34}{figure.caption.70}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {51}{\ignorespaces Code for explicitly implementing caching.\relax }}{34}{figure.caption.70}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Big Column DB}{35}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Introduction}{35}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Column wise vs. Row wise database}{35}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {52}{\ignorespaces Row-wise\relax }}{35}{figure.caption.71}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {53}{\ignorespaces Column-wise\relax }}{35}{figure.caption.72}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Column storage}{36}{subsubsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Issues with today's workloads}{36}{section*.73}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {54}{\ignorespaces Column vs. Row data storage\relax }}{36}{figure.caption.74}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {55}{\ignorespaces Row based always read the entire row (constant time). Column based instead are more efficient when few bytes have to be read. Then there is a breakeven point after which row based databases become more efficient to read data.\relax }}{37}{figure.caption.75}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {56}{\ignorespaces Tuple reconstruction.\relax }}{37}{figure.caption.75}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Compression}{37}{section*.76}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {57}{\ignorespaces Column compression example using Run Length encoding\relax }}{37}{figure.caption.77}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Cassandra}{38}{subsection.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {58}{\ignorespaces Cassandra Data Model\relax }}{38}{figure.caption.78}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {59}{\ignorespaces Cassandra properties w.r.t. RDBMS (e.g., Oracle)\relax }}{38}{figure.caption.79}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Cassandra Properties}{39}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Gossip Protocol}{39}{subsubsection.5.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {60}{\ignorespaces Cassandra Gossip Protocol\relax }}{39}{figure.caption.80}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Replica Placement Strategies}{39}{subsubsection.5.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {61}{\ignorespaces Cassandra's topology can be imagined as a ring, in which nodes are all equivalent (master-less). The process of replication is managed by a coordinator (who changes each time), who's in charge of handling the a write operation and then start propagating the new value to the others. The replicas in turn, will continue propagating the new value in an asynchronous way, following the clockwise direction.\relax }}{40}{figure.caption.81}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Write operation}{40}{subsubsection.5.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.5}Read operation}{41}{subsubsection.5.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.6}Cassandra Quorums and Consistency Levels}{41}{subsubsection.5.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {62}{\ignorespaces Cassandra write consistency\relax }}{42}{figure.caption.83}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {63}{\ignorespaces Cassandra read consistency\relax }}{42}{figure.caption.84}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.7}Data model}{42}{subsubsection.5.2.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {64}{\ignorespaces Cassandra data model\relax }}{42}{figure.caption.85}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {65}{\ignorespaces Cassandra column families are sparse tables. Some rows may contain all columns, while in other rows there could be only some of them. As in this case, row 104 has only one column while row 103 has 4 columns.\relax }}{42}{figure.caption.86}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {66}{\ignorespaces Cassandra: hybrid key-value based + column based database.\relax }}{43}{figure.caption.87}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {67}{\ignorespaces Cassandra supercolumn\relax }}{43}{figure.caption.88}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {68}{\ignorespaces Supercolumn families\relax }}{43}{figure.caption.89}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.8}What about...SQL?}{43}{subsubsection.5.2.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {69}{\ignorespaces Given the schema defined above, how could we support the presented query? We just create a new column family $UserCity$ which supports our query. In this case we are querying on the city attribute, that's why the new column family contains all the IDs of the users in that city.\relax }}{44}{figure.caption.90}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {70}{\ignorespaces RDBMS schema are rigid schema defined when building up the database. Cassandra schema is more flexible because new column families are continuously added according to query needs. \relax }}{44}{figure.caption.91}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Is Cassandra a good fit?}{44}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Vs. SQL}{45}{section*.92}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Document-oriented DB}{45}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Why document-based?}{45}{subsection.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {71}{\ignorespaces Example of document (invoice) stored in a document-based database.\relax }}{46}{figure.caption.93}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {72}{\ignorespaces Example of JSON document\relax }}{46}{figure.caption.94}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}MongoDB}{46}{subsection.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {73}{\ignorespaces MongoDB features.\relax }}{46}{figure.caption.95}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {74}{\ignorespaces MongoDB terminology vs SQL.\relax }}{47}{figure.caption.96}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Facts}{47}{subsubsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Data Model}{47}{subsubsection.6.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {75}{\ignorespaces A collection includes a set of documents.\relax }}{47}{figure.caption.97}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {76}{\ignorespaces Structure of a JSON-document. The value of field could be one of: native data types, arrays, other documents. \uline  {Rule: every document must have an \_id.}\relax }}{47}{figure.caption.97}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {77}{\ignorespaces Embdedded documents.\relax }}{47}{figure.caption.98}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {78}{\ignorespaces Reference documents or linking documents.\relax }}{47}{figure.caption.98}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.3}Queries}{48}{subsubsection.6.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {79}{\ignorespaces Read queries compared to SQL.\relax }}{48}{figure.caption.99}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {80}{\ignorespaces Comparison operators.\relax }}{48}{figure.caption.99}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.4}CAP Theorem and Mongo}{48}{subsubsection.6.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Streaming Data Engineering}{48}{section.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {81}{\ignorespaces Logical architecture of a Big Data Platform.\relax }}{48}{figure.caption.100}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}The Solution Space}{49}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}The Dimensions: Throughput vs. Latency vs. Message size}{49}{subsubsection.7.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {82}{\ignorespaces Latency-Throughput trade-off\relax }}{49}{figure.caption.103}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Three Cases along a continuum}{50}{subsubsection.7.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {83}{\ignorespaces Three cases and their latency-throughput trade-off.\relax }}{50}{figure.caption.104}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Ultra Bulk Case:}{50}{section*.105}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {84}{\ignorespaces With \href  {https://cloud.google.com/transfer-appliance/}{Google Cloud Transfer Appliance}, you need only 2 days to upload 1PB to cloud.\relax }}{50}{figure.caption.106}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Continuous Case}{50}{section*.107}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Batch Case}{51}{section*.109}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}The Batch Case}{51}{subsection.7.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {85}{\ignorespaces Overwrite option\relax }}{52}{figure.caption.111}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {86}{\ignorespaces Batch option (1st batch case)\relax }}{52}{figure.caption.111}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {87}{\ignorespaces Append vs. Compaction mode\relax }}{52}{figure.caption.114}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}The Continuous Case}{53}{subsection.7.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {88}{\ignorespaces The continuous case is based on this paradigm shift.\relax }}{53}{figure.caption.115}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {89}{\ignorespaces Many path to the same destination...\relax }}{53}{figure.caption.116}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}From Passive to Active DBMS and DSMS}{53}{subsubsection.7.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Active DBMSs}{53}{section*.117}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Data Stream Management Systems (DSMS)}{54}{section*.118}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {90}{\ignorespaces Unbounded window of data: up to a certain point is finite but it grows infinitely\relax }}{54}{figure.caption.119}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {91}{\ignorespaces Continuous queries registered over strems that are observed through windows.\relax }}{54}{figure.caption.120}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Time Model:}{54}{section*.121}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {92}{\ignorespaces We don't know the distance between e1 and e2, we only know that e2 is after e1. The order can be exploited to perform queries like \textit  {Does Alice meet Bob before Carl?}\relax }}{54}{figure.caption.122}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {93}{\ignorespaces We can ask the queries presented in the causal model. WE can start to compose queries taking into account the time \textit  {How many people has Alice met in the last 5m} (window of 5mins opened in the past) or \textit  {Does Diana meet Bob and then Carl withing 5m?} (window opened in the future).\relax }}{54}{figure.caption.123}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {94}{\ignorespaces We can ask the queries presented in the previous cases. It is possible to write even more complex queries like \textit  {Which are the meetings that last less than 5m?} or \textit  {Which are the meetings with conflicts?}\relax }}{55}{figure.caption.124}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}Event-based systems}{55}{subsubsection.7.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {95}{\ignorespaces Event-based system. Some components are publishing events and some others are listening for specific events. In this example, the up left component is listening for events that include "fire" happening in any place (* placeholder).\relax }}{55}{figure.caption.125}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Complex Event Processing (CEP)}{56}{section*.126}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {96}{\ignorespaces An idea of how a CEP system might look.\relax }}{56}{figure.caption.127}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {97}{\ignorespaces CEP semantics, a subset of Allen's semantics\relax }}{56}{figure.caption.128}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {98}{\ignorespaces Example of CEP detecting languages by \textit  {Cugola, G. and Margara, A., 2010, July. TESLA: a formally defined event specification language.}\relax }}{56}{figure.caption.129}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.3}Service Oriented Architecture (SOA)}{57}{subsubsection.7.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {99}{\ignorespaces Evolution of software architectures.\relax }}{57}{figure.caption.130}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\uline  {Monolithic Architecture}}{57}{section*.131}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\uline  {Service Oriented Architecture}}{58}{section*.132}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\uline  {Microservice Architecture}}{58}{section*.133}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\uline  {Event-Driven Architecture (EDA)}}{59}{section*.134}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {100}{\ignorespaces How it works an event-driven architecture\relax }}{60}{figure.caption.135}\protected@file@percent }
\bibstyle{unsrt}
\bibcite{slides}{1}
\bibcite{neo4j-book}{2}
\bibcite{mongodb-keyvalue}{3}
\bibcite{redis}{4}
\bibcite{redis-commands}{5}
\bibcite{columnar}{6}
\bibcite{row-vs-columnar}{7}
\bibcite{columnar-redshit}{8}
\bibcite{gossip-protocol}{9}
\bibcite{gossip-protocol}{10}
\bibcite{document-db}{11}
\bibcite{mongodb-cap}{12}
\bibcite{big-data-arch}{13}
\bibcite{event-driven}{14}
\bibcite{cep1}{15}
\bibcite{cep2}{16}
\bibcite{monolith-soa-micro}{17}
\bibcite{event-driven-arch}{18}
